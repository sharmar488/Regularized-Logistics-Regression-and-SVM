{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "rndhQ31slSQo"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import make_scorer, hinge_loss\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nbAemhDaq4xs"
   },
   "source": [
    "## Importing and pre-processing Breast Cancer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "v1F4KAHWq9Yl",
    "outputId": "067a9bf1-53a9-487c-fe68-dce539edb9a6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1:-0.860107</td>\n",
       "      <td>2:-0.111111</td>\n",
       "      <td>3:-1</td>\n",
       "      <td>4:-1</td>\n",
       "      <td>5:-1</td>\n",
       "      <td>6:-0.777778</td>\n",
       "      <td>7:-1</td>\n",
       "      <td>8:-0.555556</td>\n",
       "      <td>9:-1</td>\n",
       "      <td>10:-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1:-0.859671</td>\n",
       "      <td>2:-0.111111</td>\n",
       "      <td>3:-0.333333</td>\n",
       "      <td>4:-0.333333</td>\n",
       "      <td>5:-0.111111</td>\n",
       "      <td>6:0.333333</td>\n",
       "      <td>7:1</td>\n",
       "      <td>8:-0.555556</td>\n",
       "      <td>9:-0.777778</td>\n",
       "      <td>10:-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1:-0.857807</td>\n",
       "      <td>2:-0.555556</td>\n",
       "      <td>3:-1</td>\n",
       "      <td>4:-1</td>\n",
       "      <td>5:-1</td>\n",
       "      <td>6:-0.777778</td>\n",
       "      <td>7:-0.777778</td>\n",
       "      <td>8:-0.555556</td>\n",
       "      <td>9:-1</td>\n",
       "      <td>10:-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1:-0.85768</td>\n",
       "      <td>2:0.111111</td>\n",
       "      <td>3:0.555556</td>\n",
       "      <td>4:0.555556</td>\n",
       "      <td>5:-1</td>\n",
       "      <td>6:-0.555556</td>\n",
       "      <td>7:-0.333333</td>\n",
       "      <td>8:-0.555556</td>\n",
       "      <td>9:0.333333</td>\n",
       "      <td>10:-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1:-0.857569</td>\n",
       "      <td>2:-0.333333</td>\n",
       "      <td>3:-1</td>\n",
       "      <td>4:-1</td>\n",
       "      <td>5:-0.555556</td>\n",
       "      <td>6:-0.777778</td>\n",
       "      <td>7:-1</td>\n",
       "      <td>8:-0.555556</td>\n",
       "      <td>9:-1</td>\n",
       "      <td>10:-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0            1            2            3            4            5   \\\n",
       "0   2  1:-0.860107  2:-0.111111         3:-1         4:-1         5:-1   \n",
       "1   2  1:-0.859671  2:-0.111111  3:-0.333333  4:-0.333333  5:-0.111111   \n",
       "2   2  1:-0.857807  2:-0.555556         3:-1         4:-1         5:-1   \n",
       "3   2   1:-0.85768   2:0.111111   3:0.555556   4:0.555556         5:-1   \n",
       "4   2  1:-0.857569  2:-0.333333         3:-1         4:-1  5:-0.555556   \n",
       "\n",
       "            6            7            8            9      10  11  \n",
       "0  6:-0.777778         7:-1  8:-0.555556         9:-1  10:-1 NaN  \n",
       "1   6:0.333333          7:1  8:-0.555556  9:-0.777778  10:-1 NaN  \n",
       "2  6:-0.777778  7:-0.777778  8:-0.555556         9:-1  10:-1 NaN  \n",
       "3  6:-0.555556  7:-0.333333  8:-0.555556   9:0.333333  10:-1 NaN  \n",
       "4  6:-0.777778         7:-1  8:-0.555556         9:-1  10:-1 NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading the whole data set from the text file.\n",
    "data = pd.read_csv(\"C:\\\\Users\\\\Rahul\\\\Documents\\\\CS-688\\\\data_assignment4\\\\data_assignment4\\\\breast-cancer_scale.txt\", header=None, sep=\" \")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "87TcrD6g0Y_I",
    "outputId": "2655e0ab-eaa6-4066-d2d9-94bf4ef9b873"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2\n",
       "1      2\n",
       "2      2\n",
       "3      2\n",
       "4      2\n",
       "      ..\n",
       "678    2\n",
       "679    2\n",
       "680    4\n",
       "681    4\n",
       "682    4\n",
       "Name: 0, Length: 683, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data.iloc[:,0]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Xphk4lpl1El-",
    "outputId": "026d31b9-5a51-429b-deb7-87416c9572d8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1:-0.860107</td>\n",
       "      <td>2:-0.111111</td>\n",
       "      <td>3:-1</td>\n",
       "      <td>4:-1</td>\n",
       "      <td>5:-1</td>\n",
       "      <td>6:-0.777778</td>\n",
       "      <td>7:-1</td>\n",
       "      <td>8:-0.555556</td>\n",
       "      <td>9:-1</td>\n",
       "      <td>10:-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1:-0.859671</td>\n",
       "      <td>2:-0.111111</td>\n",
       "      <td>3:-0.333333</td>\n",
       "      <td>4:-0.333333</td>\n",
       "      <td>5:-0.111111</td>\n",
       "      <td>6:0.333333</td>\n",
       "      <td>7:1</td>\n",
       "      <td>8:-0.555556</td>\n",
       "      <td>9:-0.777778</td>\n",
       "      <td>10:-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1:-0.857807</td>\n",
       "      <td>2:-0.555556</td>\n",
       "      <td>3:-1</td>\n",
       "      <td>4:-1</td>\n",
       "      <td>5:-1</td>\n",
       "      <td>6:-0.777778</td>\n",
       "      <td>7:-0.777778</td>\n",
       "      <td>8:-0.555556</td>\n",
       "      <td>9:-1</td>\n",
       "      <td>10:-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1:-0.85768</td>\n",
       "      <td>2:0.111111</td>\n",
       "      <td>3:0.555556</td>\n",
       "      <td>4:0.555556</td>\n",
       "      <td>5:-1</td>\n",
       "      <td>6:-0.555556</td>\n",
       "      <td>7:-0.333333</td>\n",
       "      <td>8:-0.555556</td>\n",
       "      <td>9:0.333333</td>\n",
       "      <td>10:-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1:-0.857569</td>\n",
       "      <td>2:-0.333333</td>\n",
       "      <td>3:-1</td>\n",
       "      <td>4:-1</td>\n",
       "      <td>5:-0.555556</td>\n",
       "      <td>6:-0.777778</td>\n",
       "      <td>7:-1</td>\n",
       "      <td>8:-0.555556</td>\n",
       "      <td>9:-1</td>\n",
       "      <td>10:-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            1            2            3            4            5   \\\n",
       "0  1:-0.860107  2:-0.111111         3:-1         4:-1         5:-1   \n",
       "1  1:-0.859671  2:-0.111111  3:-0.333333  4:-0.333333  5:-0.111111   \n",
       "2  1:-0.857807  2:-0.555556         3:-1         4:-1         5:-1   \n",
       "3   1:-0.85768   2:0.111111   3:0.555556   4:0.555556         5:-1   \n",
       "4  1:-0.857569  2:-0.333333         3:-1         4:-1  5:-0.555556   \n",
       "\n",
       "            6            7            8            9      10  \n",
       "0  6:-0.777778         7:-1  8:-0.555556         9:-1  10:-1  \n",
       "1   6:0.333333          7:1  8:-0.555556  9:-0.777778  10:-1  \n",
       "2  6:-0.777778  7:-0.777778  8:-0.555556         9:-1  10:-1  \n",
       "3  6:-0.555556  7:-0.333333  8:-0.555556   9:0.333333  10:-1  \n",
       "4  6:-0.777778         7:-1  8:-0.555556         9:-1  10:-1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop([0,11], axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "PEa9nGgHsxpq",
    "outputId": "19e89971-bd40-45bd-a8a0-fb59f6213084"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.860107</td>\n",
       "      <td>-0.111111</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.777778</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.555556</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.859671</td>\n",
       "      <td>-0.111111</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.555556</td>\n",
       "      <td>-0.777778</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.857807</td>\n",
       "      <td>-0.555556</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.777778</td>\n",
       "      <td>-0.777778</td>\n",
       "      <td>-0.555556</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.85768</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.555556</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.555556</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.857569</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.555556</td>\n",
       "      <td>-0.777778</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.555556</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>-0.89346</td>\n",
       "      <td>-0.555556</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.555556</td>\n",
       "      <td>-0.777778</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>-0.883744</td>\n",
       "      <td>-0.777778</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.777778</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>-0.876716</td>\n",
       "      <td>-0.111111</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.555556</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>-0.875424</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.555556</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>-0.875424</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>-0.111111</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.111111</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>683 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            1          2          3          4          5          6   \\\n",
       "0    -0.860107  -0.111111         -1         -1         -1  -0.777778   \n",
       "1    -0.859671  -0.111111  -0.333333  -0.333333  -0.111111   0.333333   \n",
       "2    -0.857807  -0.555556         -1         -1         -1  -0.777778   \n",
       "3     -0.85768   0.111111   0.555556   0.555556         -1  -0.555556   \n",
       "4    -0.857569  -0.333333         -1         -1  -0.555556  -0.777778   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "678   -0.89346  -0.555556         -1         -1         -1  -0.555556   \n",
       "679  -0.883744  -0.777778         -1         -1         -1  -0.777778   \n",
       "680  -0.876716  -0.111111          1          1  -0.555556   0.333333   \n",
       "681  -0.875424  -0.333333   0.555556   0.111111  -0.333333  -0.555556   \n",
       "682  -0.875424  -0.333333   0.555556   0.555556  -0.111111  -0.333333   \n",
       "\n",
       "            7          8          9          10  \n",
       "0           -1  -0.555556         -1         -1  \n",
       "1            1  -0.555556  -0.777778         -1  \n",
       "2    -0.777778  -0.555556         -1         -1  \n",
       "3    -0.333333  -0.555556   0.333333         -1  \n",
       "4           -1  -0.555556         -1         -1  \n",
       "..         ...        ...        ...        ...  \n",
       "678  -0.777778         -1         -1         -1  \n",
       "679         -1         -1         -1         -1  \n",
       "680  -0.555556   0.555556          1  -0.777778  \n",
       "681  -0.333333          1   0.111111         -1  \n",
       "682  -0.111111          1  -0.333333         -1  \n",
       "\n",
       "[683 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing the colons and fetching required values in our dataset\n",
    "for i in data:\n",
    "    for j in range(len(data[i])):\n",
    "        m,n = data[i][j].split(':')\n",
    "        data[i][j] = n\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h7u4WDbP31tf",
    "outputId": "e050a8d3-24c8-485f-877e-61f7855227ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking train data features:  1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "5     0\n",
      "6     0\n",
      "7     0\n",
      "8     0\n",
      "9     0\n",
      "10    0\n",
      "dtype: int64\n",
      "checking train labels:  0\n"
     ]
    }
   ],
   "source": [
    "#checking null values\n",
    "print(\"checking train data features: \",data.isnull().sum())\n",
    "print(\"checking train labels: \",y.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MixQT3M34YhJ"
   },
   "source": [
    "## Splitting the data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-G4pd1xkZ92R"
   },
   "source": [
    "Fetching the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "veCxyV1y4bIe",
    "outputId": "3e468bc3-ba70-4075-e11c-aa748438bb2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 10,\n",
       " 13,\n",
       " 15,\n",
       " 16,\n",
       " 20,\n",
       " 21,\n",
       " 24,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 36,\n",
       " 37,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 71,\n",
       " 73,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 82,\n",
       " 83,\n",
       " 85,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 106,\n",
       " 107,\n",
       " 108,\n",
       " 110,\n",
       " 111,\n",
       " 112,\n",
       " 114,\n",
       " 116,\n",
       " 118,\n",
       " 119,\n",
       " 120,\n",
       " 122,\n",
       " 126,\n",
       " 127,\n",
       " 128,\n",
       " 130,\n",
       " 132,\n",
       " 133,\n",
       " 134,\n",
       " 135,\n",
       " 137,\n",
       " 138,\n",
       " 139,\n",
       " 141,\n",
       " 142,\n",
       " 143,\n",
       " 144,\n",
       " 145,\n",
       " 146,\n",
       " 147,\n",
       " 148,\n",
       " 149,\n",
       " 150,\n",
       " 151,\n",
       " 154,\n",
       " 155,\n",
       " 156,\n",
       " 158,\n",
       " 159,\n",
       " 161,\n",
       " 162,\n",
       " 163,\n",
       " 164,\n",
       " 165,\n",
       " 168,\n",
       " 169,\n",
       " 170,\n",
       " 171,\n",
       " 173,\n",
       " 174,\n",
       " 175,\n",
       " 176,\n",
       " 178,\n",
       " 179,\n",
       " 180,\n",
       " 181,\n",
       " 183,\n",
       " 184,\n",
       " 185,\n",
       " 186,\n",
       " 187,\n",
       " 189,\n",
       " 192,\n",
       " 193,\n",
       " 194,\n",
       " 195,\n",
       " 196,\n",
       " 197,\n",
       " 200,\n",
       " 201,\n",
       " 203,\n",
       " 204,\n",
       " 207,\n",
       " 208,\n",
       " 209,\n",
       " 210,\n",
       " 211,\n",
       " 212,\n",
       " 213,\n",
       " 215,\n",
       " 216,\n",
       " 217,\n",
       " 218,\n",
       " 219,\n",
       " 220,\n",
       " 222,\n",
       " 223,\n",
       " 226,\n",
       " 227,\n",
       " 228,\n",
       " 229,\n",
       " 230,\n",
       " 231,\n",
       " 232,\n",
       " 233,\n",
       " 234,\n",
       " 235,\n",
       " 236,\n",
       " 237,\n",
       " 238,\n",
       " 239,\n",
       " 240,\n",
       " 241,\n",
       " 243,\n",
       " 246,\n",
       " 247,\n",
       " 248,\n",
       " 249,\n",
       " 251,\n",
       " 252,\n",
       " 253,\n",
       " 254,\n",
       " 255,\n",
       " 256,\n",
       " 257,\n",
       " 258,\n",
       " 260,\n",
       " 264,\n",
       " 265,\n",
       " 266,\n",
       " 267,\n",
       " 268,\n",
       " 270,\n",
       " 271,\n",
       " 272,\n",
       " 277,\n",
       " 278,\n",
       " 279,\n",
       " 280,\n",
       " 282,\n",
       " 283,\n",
       " 285,\n",
       " 286,\n",
       " 289,\n",
       " 290,\n",
       " 291,\n",
       " 293,\n",
       " 294,\n",
       " 295,\n",
       " 298,\n",
       " 299,\n",
       " 300,\n",
       " 301,\n",
       " 302,\n",
       " 303,\n",
       " 304,\n",
       " 305,\n",
       " 309,\n",
       " 310,\n",
       " 311,\n",
       " 313,\n",
       " 315,\n",
       " 316,\n",
       " 318,\n",
       " 319,\n",
       " 320,\n",
       " 321,\n",
       " 324,\n",
       " 325,\n",
       " 326,\n",
       " 327,\n",
       " 328,\n",
       " 329,\n",
       " 330,\n",
       " 331,\n",
       " 332,\n",
       " 334,\n",
       " 335,\n",
       " 336,\n",
       " 337,\n",
       " 338,\n",
       " 339,\n",
       " 342,\n",
       " 344,\n",
       " 345,\n",
       " 346,\n",
       " 348,\n",
       " 350,\n",
       " 351,\n",
       " 352,\n",
       " 353,\n",
       " 354,\n",
       " 355,\n",
       " 356,\n",
       " 357,\n",
       " 359,\n",
       " 360,\n",
       " 361,\n",
       " 363,\n",
       " 364,\n",
       " 365,\n",
       " 366,\n",
       " 368,\n",
       " 370,\n",
       " 371,\n",
       " 372,\n",
       " 373,\n",
       " 374,\n",
       " 375,\n",
       " 376,\n",
       " 377,\n",
       " 378,\n",
       " 379,\n",
       " 380,\n",
       " 381,\n",
       " 382,\n",
       " 383,\n",
       " 387,\n",
       " 388,\n",
       " 389,\n",
       " 393,\n",
       " 394,\n",
       " 395,\n",
       " 396,\n",
       " 397,\n",
       " 398,\n",
       " 399,\n",
       " 400,\n",
       " 401,\n",
       " 402,\n",
       " 403,\n",
       " 404,\n",
       " 405,\n",
       " 406,\n",
       " 407,\n",
       " 408,\n",
       " 409,\n",
       " 410,\n",
       " 411,\n",
       " 412,\n",
       " 416,\n",
       " 417,\n",
       " 418,\n",
       " 419,\n",
       " 421,\n",
       " 422,\n",
       " 423,\n",
       " 424,\n",
       " 425,\n",
       " 426,\n",
       " 427,\n",
       " 428,\n",
       " 430,\n",
       " 432,\n",
       " 434,\n",
       " 435,\n",
       " 436,\n",
       " 437,\n",
       " 438,\n",
       " 439,\n",
       " 440,\n",
       " 441,\n",
       " 442,\n",
       " 444,\n",
       " 446,\n",
       " 447,\n",
       " 448,\n",
       " 449,\n",
       " 451,\n",
       " 452,\n",
       " 453,\n",
       " 454,\n",
       " 456,\n",
       " 458,\n",
       " 459,\n",
       " 460,\n",
       " 462,\n",
       " 463,\n",
       " 464,\n",
       " 465,\n",
       " 466,\n",
       " 468,\n",
       " 470,\n",
       " 472,\n",
       " 473,\n",
       " 474,\n",
       " 475,\n",
       " 476,\n",
       " 477,\n",
       " 478,\n",
       " 479,\n",
       " 480,\n",
       " 481,\n",
       " 482,\n",
       " 484,\n",
       " 485,\n",
       " 486,\n",
       " 487,\n",
       " 488,\n",
       " 489,\n",
       " 490,\n",
       " 491,\n",
       " 493,\n",
       " 494,\n",
       " 495,\n",
       " 498,\n",
       " 499,\n",
       " 500,\n",
       " 501,\n",
       " 503,\n",
       " 504,\n",
       " 505,\n",
       " 507,\n",
       " 508,\n",
       " 509,\n",
       " 510,\n",
       " 511,\n",
       " 512,\n",
       " 514,\n",
       " 516,\n",
       " 517,\n",
       " 518,\n",
       " 519,\n",
       " 520,\n",
       " 521,\n",
       " 522,\n",
       " 524,\n",
       " 528,\n",
       " 529,\n",
       " 530,\n",
       " 531,\n",
       " 532,\n",
       " 533,\n",
       " 535,\n",
       " 536,\n",
       " 537,\n",
       " 539,\n",
       " 540,\n",
       " 541,\n",
       " 542,\n",
       " 543,\n",
       " 544,\n",
       " 546,\n",
       " 547,\n",
       " 548,\n",
       " 549,\n",
       " 551,\n",
       " 552,\n",
       " 553,\n",
       " 554,\n",
       " 555,\n",
       " 556,\n",
       " 557,\n",
       " 558,\n",
       " 559,\n",
       " 561,\n",
       " 563,\n",
       " 565,\n",
       " 568,\n",
       " 569,\n",
       " 572,\n",
       " 573,\n",
       " 574,\n",
       " 577,\n",
       " 580,\n",
       " 582,\n",
       " 583,\n",
       " 584,\n",
       " 585,\n",
       " 589,\n",
       " 590,\n",
       " 591,\n",
       " 592,\n",
       " 593,\n",
       " 594,\n",
       " 595,\n",
       " 596,\n",
       " 597,\n",
       " 598,\n",
       " 599,\n",
       " 601,\n",
       " 603,\n",
       " 604,\n",
       " 608,\n",
       " 610,\n",
       " 612,\n",
       " 613,\n",
       " 615,\n",
       " 616,\n",
       " 618,\n",
       " 621,\n",
       " 622,\n",
       " 623,\n",
       " 624,\n",
       " 625,\n",
       " 626,\n",
       " 631,\n",
       " 633,\n",
       " 634,\n",
       " 635,\n",
       " 637,\n",
       " 639,\n",
       " 640,\n",
       " 641,\n",
       " 642,\n",
       " 643,\n",
       " 644,\n",
       " 645,\n",
       " 646,\n",
       " 647,\n",
       " 648,\n",
       " 649,\n",
       " 650,\n",
       " 651,\n",
       " 652,\n",
       " 653,\n",
       " 654,\n",
       " 655,\n",
       " 656,\n",
       " 657,\n",
       " 658,\n",
       " 659,\n",
       " 660,\n",
       " 661,\n",
       " 664,\n",
       " 665,\n",
       " 666,\n",
       " 667,\n",
       " 668,\n",
       " 669,\n",
       " 671,\n",
       " 672,\n",
       " 673,\n",
       " 674,\n",
       " 675,\n",
       " 676,\n",
       " 677,\n",
       " 681]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting the train data indices\n",
    "trainIndex = pd.read_csv(\"C:\\\\Users\\\\Rahul\\\\Documents\\\\CS-688\\\\data_assignment4\\\\data_assignment4\\\\breast-cancer-scale-train-indices.txt\", header=None)\n",
    "trainIndexlist = []\n",
    "for i,ind in enumerate(trainIndex[:][0]):\n",
    "  trainIndexlist.append(ind-1)\n",
    "#trainIndex.head()\n",
    "trainIndexlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "Z1nxDDLd8Qan",
    "outputId": "5a9b9da9-7aac-4139-b6ea-f65ee09a82fc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.857807</td>\n",
       "      <td>-0.555556</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.777778</td>\n",
       "      <td>-0.777778</td>\n",
       "      <td>-0.555556</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.857569</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.555556</td>\n",
       "      <td>-0.777778</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.555556</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.857554</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.857408</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.777778</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.555556</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.857339</td>\n",
       "      <td>-0.777778</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.777778</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.777778</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.555556</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          1          2   3          4          5          6          7   \\\n",
       "0  -0.857807  -0.555556  -1         -1         -1  -0.777778  -0.777778   \n",
       "1  -0.857569  -0.333333  -1         -1  -0.555556  -0.777778         -1   \n",
       "2  -0.857554   0.555556   1          1   0.555556   0.333333          1   \n",
       "3  -0.857408         -1  -1         -1         -1  -0.777778          1   \n",
       "4  -0.857339  -0.777778  -1  -0.777778         -1  -0.777778         -1   \n",
       "\n",
       "          8         9   10  \n",
       "0  -0.555556        -1  -1  \n",
       "1  -0.555556        -1  -1  \n",
       "2   0.777778  0.333333  -1  \n",
       "3  -0.555556        -1  -1  \n",
       "4  -0.555556        -1  -1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splitting the train data from the main data set based on train indices.\n",
    "trainData = data.iloc[trainIndexlist,:]\n",
    "trainData = trainData.reset_index(drop=True)\n",
    "trainData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7QgkNjH_ZKPc",
    "outputId": "5a37077d-5e9a-4ffe-8a7c-d4fdc91994e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    2\n",
       "2    4\n",
       "3    2\n",
       "4    2\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting the train labels\n",
    "trainLabels = y.iloc[trainIndexlist]\n",
    "trainLabels = trainLabels.reset_index(drop=True)\n",
    "trainLabels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-nr91U0KaJvZ"
   },
   "source": [
    "Fetching the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "iv-ISnB2ZpAm",
    "outputId": "7093181f-e44d-4089-9c4f-8744f3bc0720"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 3,\n",
       " 8,\n",
       " 9,\n",
       " 11,\n",
       " 12,\n",
       " 14,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 22,\n",
       " 23,\n",
       " 25,\n",
       " 26,\n",
       " 35,\n",
       " 38,\n",
       " 42,\n",
       " 43,\n",
       " 49,\n",
       " 56,\n",
       " 60,\n",
       " 64,\n",
       " 65,\n",
       " 70,\n",
       " 72,\n",
       " 74,\n",
       " 81,\n",
       " 84,\n",
       " 86,\n",
       " 87,\n",
       " 93,\n",
       " 94,\n",
       " 101,\n",
       " 109,\n",
       " 113,\n",
       " 115,\n",
       " 117,\n",
       " 121,\n",
       " 123,\n",
       " 124,\n",
       " 125,\n",
       " 129,\n",
       " 131,\n",
       " 136,\n",
       " 140,\n",
       " 152,\n",
       " 153,\n",
       " 157,\n",
       " 160,\n",
       " 166,\n",
       " 167,\n",
       " 172,\n",
       " 177,\n",
       " 182,\n",
       " 188,\n",
       " 190,\n",
       " 191,\n",
       " 198,\n",
       " 199,\n",
       " 202,\n",
       " 205,\n",
       " 206,\n",
       " 214,\n",
       " 221,\n",
       " 224,\n",
       " 225,\n",
       " 242,\n",
       " 244,\n",
       " 245,\n",
       " 250,\n",
       " 259,\n",
       " 261,\n",
       " 262,\n",
       " 263,\n",
       " 269,\n",
       " 273,\n",
       " 274,\n",
       " 275,\n",
       " 276,\n",
       " 281,\n",
       " 284,\n",
       " 287,\n",
       " 288,\n",
       " 292,\n",
       " 296,\n",
       " 297,\n",
       " 306,\n",
       " 307,\n",
       " 308,\n",
       " 312,\n",
       " 314,\n",
       " 317,\n",
       " 322,\n",
       " 323,\n",
       " 333,\n",
       " 340,\n",
       " 341,\n",
       " 343,\n",
       " 347,\n",
       " 349,\n",
       " 358,\n",
       " 362,\n",
       " 367,\n",
       " 369,\n",
       " 384,\n",
       " 385,\n",
       " 386,\n",
       " 390,\n",
       " 391,\n",
       " 392,\n",
       " 413,\n",
       " 414,\n",
       " 415,\n",
       " 420,\n",
       " 429,\n",
       " 431,\n",
       " 433,\n",
       " 443,\n",
       " 445,\n",
       " 450,\n",
       " 455,\n",
       " 457,\n",
       " 461,\n",
       " 467,\n",
       " 469,\n",
       " 471,\n",
       " 483,\n",
       " 492,\n",
       " 496,\n",
       " 497,\n",
       " 502,\n",
       " 506,\n",
       " 513,\n",
       " 515,\n",
       " 523,\n",
       " 525,\n",
       " 526,\n",
       " 527,\n",
       " 534,\n",
       " 538,\n",
       " 545,\n",
       " 550,\n",
       " 560,\n",
       " 562,\n",
       " 564,\n",
       " 566,\n",
       " 567,\n",
       " 570,\n",
       " 571,\n",
       " 575,\n",
       " 576,\n",
       " 578,\n",
       " 579,\n",
       " 581,\n",
       " 586,\n",
       " 587,\n",
       " 588,\n",
       " 600,\n",
       " 602,\n",
       " 605,\n",
       " 606,\n",
       " 607,\n",
       " 609,\n",
       " 611,\n",
       " 614,\n",
       " 617,\n",
       " 619,\n",
       " 620,\n",
       " 627,\n",
       " 628,\n",
       " 629,\n",
       " 630,\n",
       " 632,\n",
       " 636,\n",
       " 638,\n",
       " 662,\n",
       " 663,\n",
       " 670,\n",
       " 678,\n",
       " 679,\n",
       " 680,\n",
       " 682]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting the test data indices\n",
    "testIndex = pd.read_csv(\"C:\\\\Users\\\\Rahul\\\\Documents\\\\CS-688\\\\data_assignment4\\\\data_assignment4\\\\breast-cancer-scale-test-indices.txt\", header=None)\n",
    "testIndexlist = []\n",
    "for i,ind in enumerate(testIndex[:][0]):\n",
    "  testIndexlist.append(ind-1)\n",
    "testIndexlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "ll6H6AFpaUCr",
    "outputId": "1e0c4bb4-7399-4b33-f736-1433be90ea3f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.860107</td>\n",
       "      <td>-0.111111</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.777778</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.555556</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.859671</td>\n",
       "      <td>-0.111111</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.555556</td>\n",
       "      <td>-0.777778</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.85768</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.555556</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.555556</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.855171</td>\n",
       "      <td>-0.777778</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.777778</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.855171</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.777778</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.777778</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.777778</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          1          2          3          4          5          6   \\\n",
       "0  -0.860107  -0.111111         -1         -1         -1  -0.777778   \n",
       "1  -0.859671  -0.111111  -0.333333  -0.333333  -0.111111   0.333333   \n",
       "2   -0.85768   0.111111   0.555556   0.555556         -1  -0.555556   \n",
       "3  -0.855171  -0.777778         -1         -1         -1  -0.777778   \n",
       "4  -0.855171  -0.333333  -0.777778         -1         -1  -0.777778   \n",
       "\n",
       "          7          8          9          10  \n",
       "0         -1  -0.555556         -1         -1  \n",
       "1          1  -0.555556  -0.777778         -1  \n",
       "2  -0.333333  -0.555556   0.333333         -1  \n",
       "3         -1         -1         -1  -0.111111  \n",
       "4         -1  -0.777778         -1         -1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splitting the test data from the main data set based on test indices.\n",
    "testData = data.iloc[testIndexlist,:]\n",
    "testData = testData.reset_index(drop=True)\n",
    "testData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ai1gyr6Qbzz8",
    "outputId": "ceabfeb4-4c77-48b6-af88-37672c386de9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    2\n",
       "2    2\n",
       "3    2\n",
       "4    2\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting the test labels\n",
    "testLabels = y.iloc[testIndexlist]\n",
    "testLabels = testLabels.reset_index(drop=True)\n",
    "testLabels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aH6wmwb-dRGF"
   },
   "source": [
    "## Splitting train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "EDeaxvFndQqJ"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(trainData, trainLabels, random_state=47, stratify = trainLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cp-Eg90hcc_e"
   },
   "source": [
    "## Find Best C for Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EeZ_yjiuFZc9",
    "outputId": "67662c54-c6d9-46ac-d456-36739a0f9e66"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accuracy',\n",
       " 'adjusted_mutual_info_score',\n",
       " 'adjusted_rand_score',\n",
       " 'average_precision',\n",
       " 'balanced_accuracy',\n",
       " 'completeness_score',\n",
       " 'explained_variance',\n",
       " 'f1',\n",
       " 'f1_macro',\n",
       " 'f1_micro',\n",
       " 'f1_samples',\n",
       " 'f1_weighted',\n",
       " 'fowlkes_mallows_score',\n",
       " 'homogeneity_score',\n",
       " 'jaccard',\n",
       " 'jaccard_macro',\n",
       " 'jaccard_micro',\n",
       " 'jaccard_samples',\n",
       " 'jaccard_weighted',\n",
       " 'max_error',\n",
       " 'mutual_info_score',\n",
       " 'neg_brier_score',\n",
       " 'neg_log_loss',\n",
       " 'neg_mean_absolute_error',\n",
       " 'neg_mean_absolute_percentage_error',\n",
       " 'neg_mean_gamma_deviance',\n",
       " 'neg_mean_poisson_deviance',\n",
       " 'neg_mean_squared_error',\n",
       " 'neg_mean_squared_log_error',\n",
       " 'neg_median_absolute_error',\n",
       " 'neg_root_mean_squared_error',\n",
       " 'normalized_mutual_info_score',\n",
       " 'precision',\n",
       " 'precision_macro',\n",
       " 'precision_micro',\n",
       " 'precision_samples',\n",
       " 'precision_weighted',\n",
       " 'r2',\n",
       " 'rand_score',\n",
       " 'recall',\n",
       " 'recall_macro',\n",
       " 'recall_micro',\n",
       " 'recall_samples',\n",
       " 'recall_weighted',\n",
       " 'roc_auc',\n",
       " 'roc_auc_ovo',\n",
       " 'roc_auc_ovo_weighted',\n",
       " 'roc_auc_ovr',\n",
       " 'roc_auc_ovr_weighted',\n",
       " 'top_k_accuracy',\n",
       " 'v_measure_score']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sorted(sklearn.metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "oSxjrMOPckHr"
   },
   "outputs": [],
   "source": [
    "c_values = [0.1,1,10,100,1000]\n",
    "meanErrorsTraining = []\n",
    "meanErrorsValidation = []\n",
    "kfold = KFold(n_splits=5, random_state=27, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "fQQxpjbcpwru"
   },
   "outputs": [],
   "source": [
    "def findMeanSquaredErrorForC(kfold, c, X, y):\n",
    "  lr = LogisticRegression(random_state=27, C=c, solver='liblinear')\n",
    "  result = cross_val_score(lr, X, y, cv=kfold, scoring='neg_mean_squared_error')\n",
    "  return result.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "gGucP5jLEbsf"
   },
   "outputs": [],
   "source": [
    "for c in c_values:\n",
    "  meanErrorsTraining.append(findMeanSquaredErrorForC(kfold, c, X_train, y_train))\n",
    "  meanErrorsValidation.append(findMeanSquaredErrorForC(kfold, c, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ac6Bda1_JwXZ",
    "outputId": "5bfd743c-cb32-40b3-bc9d-219900999410"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors on training data for different values of c:  [-0.192, -0.1706666666666667, -0.16, -0.1706666666666667, -0.1706666666666667]\n",
      "Errors on validation data for different values of c:  [-0.096, -0.096, -0.032, -0.064, -0.064]\n"
     ]
    }
   ],
   "source": [
    "print(\"Errors on training data for different values of c: \", meanErrorsTraining)\n",
    "print(\"Errors on validation data for different values of c: \", meanErrorsValidation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SWTuh776Kffk",
    "outputId": "d291dd94-c9cc-4bb9-af34-e29bd4d5908e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best value of C:  10\n"
     ]
    }
   ],
   "source": [
    "best_value_of_c = c_values[np.argsort(-np.array(meanErrorsValidation))[0]]\n",
    "print(\"best value of C: \", best_value_of_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MIpxcXvMOEZ0"
   },
   "source": [
    "## Train the Model using the best C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k_hLRsjgOJUB",
    "outputId": "4359cfa1-c142-4f96-e808-50c574997df8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for cancer data with best C is:  0.9617486338797814\n"
     ]
    }
   ],
   "source": [
    "bestLR = LogisticRegression(random_state=27, C=10, solver='liblinear').fit(trainData, trainLabels)\n",
    "y_predLR = bestLR.predict(testData)\n",
    "print(\"accuracy for cancer data with best C is: \", accuracy_score(y_predLR, testLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "88ic_T8tO1bU",
    "outputId": "1036f78d-cc66-4ca1-f68f-92925bf512d4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error rate for testing data:  3.825136612021858 %\n"
     ]
    }
   ],
   "source": [
    "error = 0\n",
    "for i in range(len(y_predLR)):\n",
    "  if y_predLR[i] != testLabels[i]:\n",
    "    error = error + 1\n",
    "print(\"error rate for testing data: \", error/len(y_predLR)*100, \"%\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_error_svm = []\n",
    "validation_error_svm = []\n",
    "kf = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a custom score for hinge loss\n",
    "def hingeLoss(y_true, y_predict):\n",
    "  return hinge_loss(y_true, y_predict)\n",
    "\n",
    "hingeLossMetric = make_scorer(hingeLoss, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in c_values:\n",
    "  linear_svm = LinearSVC(random_state=0,C=i)\n",
    "  result = cross_val_score(linear_svm, X_train, y_train, cv=kf, scoring=hingeLossMetric)\n",
    "  training_error_svm.append(result.mean())\n",
    "  \n",
    "  result = cross_val_score(linear_svm, X_test, y_test, cv=kf, scoring=hingeLossMetric)\n",
    "  validation_error_svm.append(result.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainning data errors: [-1.984, -1.984, -1.984, -1.984, -2.1173333333333333]\n",
      "Validation data errors: [-1.9439999999999997, -1.9439999999999997, -1.9439999999999997, -1.9439999999999997, -1.9439999999999997]\n"
     ]
    }
   ],
   "source": [
    "print(\"Trainning data errors:\", training_error_svm)\n",
    "print(\"Validation data errors:\", validation_error_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n"
     ]
    }
   ],
   "source": [
    "best_value_of_c = c_values[validation_error_svm.index(min(validation_error_svm))]\n",
    "print(best_value_of_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hinge Loss for testing data:  2.0054644808743167\n"
     ]
    }
   ],
   "source": [
    "lr_svc = LinearSVC(random_state=0,C=0.1).fit(trainData, trainLabels)\n",
    "lr_svc_pred = lr_svc.predict(testData)\n",
    "accuracy = accuracy_score(lr_svc_pred, testLabels)\n",
    "\n",
    "error = 0\n",
    "for i in range(len(lr_svc_pred)):\n",
    "  if lr_svc_pred[i] != testLabels[i]:\n",
    "    error = error + 1\n",
    "error_rate = error/len(lr_svc_pred)*100\n",
    "print(\"Hinge Loss for testing data: \", hinge_loss(testLabels,lr_svc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9617486338797814\n",
      "Error rate: 3.825136612021858\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Error rate:\", error_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_error_poly = []\n",
    "validation_error_poly = []\n",
    "kf = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in c_values:\n",
    "  polysvm = SVC(random_state=0,C=i, kernel='poly')\n",
    "  result = cross_val_score(polysvm, X_train, y_train, cv=kf, scoring=hingeLossMetric)\n",
    "  training_error_poly.append(result.mean())\n",
    "  \n",
    "  result = cross_val_score(polysvm, X_test, y_test, cv=kf, scoring=hingeLossMetric)\n",
    "  validation_error_poly.append(result.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainning data errors: [-1.9893333333333334, -2.0, -2.0053333333333336, -2.0053333333333336, -2.0053333333333336]\n",
      "Validation data errors: [-1.9759999999999998, -1.9599999999999997, -1.9439999999999997, -1.9439999999999997, -1.9439999999999997]\n"
     ]
    }
   ],
   "source": [
    "print(\"Trainning data errors:\", training_error_poly)\n",
    "print(\"Validation data errors:\", validation_error_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n"
     ]
    }
   ],
   "source": [
    "best_value_of_c = c_values[validation_error_poly.index(min(validation_error_poly))]\n",
    "print(best_value_of_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hinge Loss for testing data:  2.0163934426229506\n"
     ]
    }
   ],
   "source": [
    "lr1 = SVC(random_state=0, C=0.1,kernel='poly').fit(trainData, trainLabels)\n",
    "lr1_pred = lr1.predict(testData)\n",
    "accuracy = accuracy_score(lr1_pred, testLabels)\n",
    "\n",
    "error = 0\n",
    "for i in range(len(lr1_pred)):\n",
    "  if lr1_pred[i] != testLabels[i]:\n",
    "    error = error + 1\n",
    "error_rate = error/len(lr1_pred)*100\n",
    "print(\"Hinge Loss for testing data: \", hinge_loss(testLabels,lr1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9672131147540983\n",
      "Error rate: 3.278688524590164\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Error rate:\", error_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RBF Kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_error_rbf = []\n",
    "validation_error_rbf = []\n",
    "kf = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in c_values:\n",
    "  rbfsvm = SVC(random_state=0, C=i,kernel='rbf')\n",
    "  result = cross_val_score(rbfsvm, X_train, y_train, cv=kf, scoring=hingeLossMetric)\n",
    "  training_error_rbf.append(result.mean())\n",
    "  \n",
    "  result = cross_val_score(rbfsvm, X_test, y_test, cv=kf, scoring=hingeLossMetric)\n",
    "  validation_error_rbf.append(result.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainning data errors: [-1.9946666666666666, -1.9893333333333334, -1.9946666666666668, -2.0, -2.0]\n",
      "Validation data errors: [-1.9599999999999997, -1.9439999999999997, -1.9439999999999997, -1.9439999999999997, -1.9439999999999997]\n"
     ]
    }
   ],
   "source": [
    "print(\"Trainning data errors:\", training_error_rbf)\n",
    "print(\"Validation data errors:\", validation_error_rbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n"
     ]
    }
   ],
   "source": [
    "best_value_of_c = c_values[validation_error_rbf.index(min(validation_error_rbf))]\n",
    "print(best_value_of_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hinge Loss for testing data:  2.0054644808743167\n"
     ]
    }
   ],
   "source": [
    "lr1 = SVC(random_state=0, C=0.1,kernel='rbf').fit(trainData, trainLabels)\n",
    "lr1_pred = lr1.predict(testData)\n",
    "accuracy = accuracy_score(lr1_pred, testLabels)\n",
    "\n",
    "error = 0\n",
    "for i in range(len(lr1_pred)):\n",
    "  if lr1_pred[i] != testLabels[i]:\n",
    "    error = error + 1\n",
    "error_rate = error/len(lr1_pred)*100\n",
    "print(\"Hinge Loss for testing data: \", hinge_loss(testLabels,lr1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is: 0.9617486338797814\n",
      "Error rate: 3.825136612021858\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of the model is:\", accuracy)\n",
    "print(\"Error rate:\", error_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FB26jgPfQO73"
   },
   "source": [
    "# Sonar Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1:-0.727139</td>\n",
       "      <td>2:-0.687098</td>\n",
       "      <td>3:-0.728647</td>\n",
       "      <td>4:-0.929149</td>\n",
       "      <td>5:-0.550089</td>\n",
       "      <td>6:-0.524859</td>\n",
       "      <td>7:-0.185065</td>\n",
       "      <td>8:-0.318192</td>\n",
       "      <td>9:-0.101436</td>\n",
       "      <td>...</td>\n",
       "      <td>52:-0.945792</td>\n",
       "      <td>53:-0.688312</td>\n",
       "      <td>54:-0.128655</td>\n",
       "      <td>55:-0.70068</td>\n",
       "      <td>56:-0.164103</td>\n",
       "      <td>57:0.00568182</td>\n",
       "      <td>58:-0.629291</td>\n",
       "      <td>59:-0.509642</td>\n",
       "      <td>60:-0.879908</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1:-0.353982</td>\n",
       "      <td>2:-0.556794</td>\n",
       "      <td>3:-0.455979</td>\n",
       "      <td>4:-0.699952</td>\n",
       "      <td>5:-0.433934</td>\n",
       "      <td>6:0.333512</td>\n",
       "      <td>7:0.14881</td>\n",
       "      <td>8:0.510915</td>\n",
       "      <td>9:-0.0339109</td>\n",
       "      <td>...</td>\n",
       "      <td>52:-0.783167</td>\n",
       "      <td>53:-0.563636</td>\n",
       "      <td>54:-0.777778</td>\n",
       "      <td>55:-0.600907</td>\n",
       "      <td>56:-0.0410256</td>\n",
       "      <td>57:-0.221591</td>\n",
       "      <td>58:-0.789474</td>\n",
       "      <td>59:-0.719008</td>\n",
       "      <td>60:-0.82448</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1:-0.635693</td>\n",
       "      <td>2:-0.506215</td>\n",
       "      <td>3:-0.287779</td>\n",
       "      <td>4:-0.512601</td>\n",
       "      <td>5:-0.539944</td>\n",
       "      <td>6:0.170653</td>\n",
       "      <td>7:0.297619</td>\n",
       "      <td>8:0.638809</td>\n",
       "      <td>9:0.635717</td>\n",
       "      <td>...</td>\n",
       "      <td>52:-0.360913</td>\n",
       "      <td>53:-0.163636</td>\n",
       "      <td>54:-0.502924</td>\n",
       "      <td>55:-0.210884</td>\n",
       "      <td>56:0.230769</td>\n",
       "      <td>57:0.778409</td>\n",
       "      <td>58:-0.263158</td>\n",
       "      <td>59:-0.482094</td>\n",
       "      <td>60:-0.667436</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1:-0.874631</td>\n",
       "      <td>2:-0.858551</td>\n",
       "      <td>3:-0.600526</td>\n",
       "      <td>4:-0.9301</td>\n",
       "      <td>5:-0.930003</td>\n",
       "      <td>6:-0.857028</td>\n",
       "      <td>7:-0.423701</td>\n",
       "      <td>8:-0.461521</td>\n",
       "      <td>9:-0.845106</td>\n",
       "      <td>...</td>\n",
       "      <td>52:-0.677603</td>\n",
       "      <td>53:-0.838961</td>\n",
       "      <td>54:-0.181287</td>\n",
       "      <td>55:-0.641723</td>\n",
       "      <td>56:-0.646154</td>\n",
       "      <td>57:-0.732955</td>\n",
       "      <td>58:-0.812357</td>\n",
       "      <td>59:-0.785124</td>\n",
       "      <td>60:-0.487298</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1:0.10177</td>\n",
       "      <td>2:-0.434205</td>\n",
       "      <td>3:-0.693824</td>\n",
       "      <td>4:-0.840228</td>\n",
       "      <td>5:-0.73472</td>\n",
       "      <td>6:-0.705993</td>\n",
       "      <td>7:-0.363636</td>\n",
       "      <td>8:0.0637266</td>\n",
       "      <td>9:0.0333185</td>\n",
       "      <td>...</td>\n",
       "      <td>52:-0.934379</td>\n",
       "      <td>53:-0.745455</td>\n",
       "      <td>54:-0.444444</td>\n",
       "      <td>55:-0.528345</td>\n",
       "      <td>56:-0.94359</td>\n",
       "      <td>57:-0.607955</td>\n",
       "      <td>58:-0.79405</td>\n",
       "      <td>59:-0.415978</td>\n",
       "      <td>60:-0.593533</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0            1            2            3            4            5   \\\n",
       "0   1  1:-0.727139  2:-0.687098  3:-0.728647  4:-0.929149  5:-0.550089   \n",
       "1   1  1:-0.353982  2:-0.556794  3:-0.455979  4:-0.699952  5:-0.433934   \n",
       "2   1  1:-0.635693  2:-0.506215  3:-0.287779  4:-0.512601  5:-0.539944   \n",
       "3   1  1:-0.874631  2:-0.858551  3:-0.600526    4:-0.9301  5:-0.930003   \n",
       "4   1    1:0.10177  2:-0.434205  3:-0.693824  4:-0.840228   5:-0.73472   \n",
       "\n",
       "            6            7            8             9   ...            52  \\\n",
       "0  6:-0.524859  7:-0.185065  8:-0.318192   9:-0.101436  ...  52:-0.945792   \n",
       "1   6:0.333512    7:0.14881   8:0.510915  9:-0.0339109  ...  52:-0.783167   \n",
       "2   6:0.170653   7:0.297619   8:0.638809    9:0.635717  ...  52:-0.360913   \n",
       "3  6:-0.857028  7:-0.423701  8:-0.461521   9:-0.845106  ...  52:-0.677603   \n",
       "4  6:-0.705993  7:-0.363636  8:0.0637266   9:0.0333185  ...  52:-0.934379   \n",
       "\n",
       "             53            54            55             56             57  \\\n",
       "0  53:-0.688312  54:-0.128655   55:-0.70068   56:-0.164103  57:0.00568182   \n",
       "1  53:-0.563636  54:-0.777778  55:-0.600907  56:-0.0410256   57:-0.221591   \n",
       "2  53:-0.163636  54:-0.502924  55:-0.210884    56:0.230769    57:0.778409   \n",
       "3  53:-0.838961  54:-0.181287  55:-0.641723   56:-0.646154   57:-0.732955   \n",
       "4  53:-0.745455  54:-0.444444  55:-0.528345    56:-0.94359   57:-0.607955   \n",
       "\n",
       "             58            59            60  61  \n",
       "0  58:-0.629291  59:-0.509642  60:-0.879908 NaN  \n",
       "1  58:-0.789474  59:-0.719008   60:-0.82448 NaN  \n",
       "2  58:-0.263158  59:-0.482094  60:-0.667436 NaN  \n",
       "3  58:-0.812357  59:-0.785124  60:-0.487298 NaN  \n",
       "4   58:-0.79405  59:-0.415978  60:-0.593533 NaN  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading the whole data set from the text file.\n",
    "sonar_data = pd.read_csv(\"C:\\\\Users\\\\Rahul\\\\Documents\\\\CS-688\\\\data_assignment4\\\\data_assignment4\\\\sonar_scale.txt\", header=None, sep=\" \")\n",
    "sonar_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "203   -1\n",
       "204   -1\n",
       "205   -1\n",
       "206   -1\n",
       "207   -1\n",
       "Name: 0, Length: 208, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sonar_y = sonar_data.iloc[:,0]\n",
    "sonar_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1:-0.727139</td>\n",
       "      <td>2:-0.687098</td>\n",
       "      <td>3:-0.728647</td>\n",
       "      <td>4:-0.929149</td>\n",
       "      <td>5:-0.550089</td>\n",
       "      <td>6:-0.524859</td>\n",
       "      <td>7:-0.185065</td>\n",
       "      <td>8:-0.318192</td>\n",
       "      <td>9:-0.101436</td>\n",
       "      <td>10:-0.428571</td>\n",
       "      <td>...</td>\n",
       "      <td>51:-0.537849</td>\n",
       "      <td>52:-0.945792</td>\n",
       "      <td>53:-0.688312</td>\n",
       "      <td>54:-0.128655</td>\n",
       "      <td>55:-0.70068</td>\n",
       "      <td>56:-0.164103</td>\n",
       "      <td>57:0.00568182</td>\n",
       "      <td>58:-0.629291</td>\n",
       "      <td>59:-0.509642</td>\n",
       "      <td>60:-0.879908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1:-0.353982</td>\n",
       "      <td>2:-0.556794</td>\n",
       "      <td>3:-0.455979</td>\n",
       "      <td>4:-0.699952</td>\n",
       "      <td>5:-0.433934</td>\n",
       "      <td>6:0.333512</td>\n",
       "      <td>7:0.14881</td>\n",
       "      <td>8:0.510915</td>\n",
       "      <td>9:-0.0339109</td>\n",
       "      <td>10:-0.210925</td>\n",
       "      <td>...</td>\n",
       "      <td>51:-0.750996</td>\n",
       "      <td>52:-0.783167</td>\n",
       "      <td>53:-0.563636</td>\n",
       "      <td>54:-0.777778</td>\n",
       "      <td>55:-0.600907</td>\n",
       "      <td>56:-0.0410256</td>\n",
       "      <td>57:-0.221591</td>\n",
       "      <td>58:-0.789474</td>\n",
       "      <td>59:-0.719008</td>\n",
       "      <td>60:-0.82448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1:-0.635693</td>\n",
       "      <td>2:-0.506215</td>\n",
       "      <td>3:-0.287779</td>\n",
       "      <td>4:-0.512601</td>\n",
       "      <td>5:-0.539944</td>\n",
       "      <td>6:0.170653</td>\n",
       "      <td>7:0.297619</td>\n",
       "      <td>8:0.638809</td>\n",
       "      <td>9:0.635717</td>\n",
       "      <td>10:0.739168</td>\n",
       "      <td>...</td>\n",
       "      <td>51:-0.934263</td>\n",
       "      <td>52:-0.360913</td>\n",
       "      <td>53:-0.163636</td>\n",
       "      <td>54:-0.502924</td>\n",
       "      <td>55:-0.210884</td>\n",
       "      <td>56:0.230769</td>\n",
       "      <td>57:0.778409</td>\n",
       "      <td>58:-0.263158</td>\n",
       "      <td>59:-0.482094</td>\n",
       "      <td>60:-0.667436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1:-0.874631</td>\n",
       "      <td>2:-0.858551</td>\n",
       "      <td>3:-0.600526</td>\n",
       "      <td>4:-0.9301</td>\n",
       "      <td>5:-0.930003</td>\n",
       "      <td>6:-0.857028</td>\n",
       "      <td>7:-0.423701</td>\n",
       "      <td>8:-0.461521</td>\n",
       "      <td>9:-0.845106</td>\n",
       "      <td>10:-0.670814</td>\n",
       "      <td>...</td>\n",
       "      <td>51:-0.51992</td>\n",
       "      <td>52:-0.677603</td>\n",
       "      <td>53:-0.838961</td>\n",
       "      <td>54:-0.181287</td>\n",
       "      <td>55:-0.641723</td>\n",
       "      <td>56:-0.646154</td>\n",
       "      <td>57:-0.732955</td>\n",
       "      <td>58:-0.812357</td>\n",
       "      <td>59:-0.785124</td>\n",
       "      <td>60:-0.487298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1:0.10177</td>\n",
       "      <td>2:-0.434205</td>\n",
       "      <td>3:-0.693824</td>\n",
       "      <td>4:-0.840228</td>\n",
       "      <td>5:-0.73472</td>\n",
       "      <td>6:-0.705993</td>\n",
       "      <td>7:-0.363636</td>\n",
       "      <td>8:0.0637266</td>\n",
       "      <td>9:0.0333185</td>\n",
       "      <td>10:0.242957</td>\n",
       "      <td>...</td>\n",
       "      <td>51:-0.689243</td>\n",
       "      <td>52:-0.934379</td>\n",
       "      <td>53:-0.745455</td>\n",
       "      <td>54:-0.444444</td>\n",
       "      <td>55:-0.528345</td>\n",
       "      <td>56:-0.94359</td>\n",
       "      <td>57:-0.607955</td>\n",
       "      <td>58:-0.79405</td>\n",
       "      <td>59:-0.415978</td>\n",
       "      <td>60:-0.593533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            1            2            3            4            5   \\\n",
       "0  1:-0.727139  2:-0.687098  3:-0.728647  4:-0.929149  5:-0.550089   \n",
       "1  1:-0.353982  2:-0.556794  3:-0.455979  4:-0.699952  5:-0.433934   \n",
       "2  1:-0.635693  2:-0.506215  3:-0.287779  4:-0.512601  5:-0.539944   \n",
       "3  1:-0.874631  2:-0.858551  3:-0.600526    4:-0.9301  5:-0.930003   \n",
       "4    1:0.10177  2:-0.434205  3:-0.693824  4:-0.840228   5:-0.73472   \n",
       "\n",
       "            6            7            8             9             10  ...  \\\n",
       "0  6:-0.524859  7:-0.185065  8:-0.318192   9:-0.101436  10:-0.428571  ...   \n",
       "1   6:0.333512    7:0.14881   8:0.510915  9:-0.0339109  10:-0.210925  ...   \n",
       "2   6:0.170653   7:0.297619   8:0.638809    9:0.635717   10:0.739168  ...   \n",
       "3  6:-0.857028  7:-0.423701  8:-0.461521   9:-0.845106  10:-0.670814  ...   \n",
       "4  6:-0.705993  7:-0.363636  8:0.0637266   9:0.0333185   10:0.242957  ...   \n",
       "\n",
       "             51            52            53            54            55  \\\n",
       "0  51:-0.537849  52:-0.945792  53:-0.688312  54:-0.128655   55:-0.70068   \n",
       "1  51:-0.750996  52:-0.783167  53:-0.563636  54:-0.777778  55:-0.600907   \n",
       "2  51:-0.934263  52:-0.360913  53:-0.163636  54:-0.502924  55:-0.210884   \n",
       "3   51:-0.51992  52:-0.677603  53:-0.838961  54:-0.181287  55:-0.641723   \n",
       "4  51:-0.689243  52:-0.934379  53:-0.745455  54:-0.444444  55:-0.528345   \n",
       "\n",
       "              56             57            58            59            60  \n",
       "0   56:-0.164103  57:0.00568182  58:-0.629291  59:-0.509642  60:-0.879908  \n",
       "1  56:-0.0410256   57:-0.221591  58:-0.789474  59:-0.719008   60:-0.82448  \n",
       "2    56:0.230769    57:0.778409  58:-0.263158  59:-0.482094  60:-0.667436  \n",
       "3   56:-0.646154   57:-0.732955  58:-0.812357  59:-0.785124  60:-0.487298  \n",
       "4    56:-0.94359   57:-0.607955   58:-0.79405  59:-0.415978  60:-0.593533  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sonar_data.drop([0,61], axis=1, inplace=True)\n",
    "sonar_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking train data features:  1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "5     0\n",
      "6     0\n",
      "7     0\n",
      "8     0\n",
      "9     0\n",
      "10    0\n",
      "11    0\n",
      "12    0\n",
      "13    0\n",
      "14    0\n",
      "15    0\n",
      "16    0\n",
      "17    0\n",
      "18    0\n",
      "19    0\n",
      "20    0\n",
      "21    0\n",
      "22    0\n",
      "23    0\n",
      "24    0\n",
      "25    0\n",
      "26    0\n",
      "27    0\n",
      "28    0\n",
      "29    0\n",
      "30    0\n",
      "31    0\n",
      "32    0\n",
      "33    0\n",
      "34    0\n",
      "35    0\n",
      "36    0\n",
      "37    0\n",
      "38    0\n",
      "39    0\n",
      "40    0\n",
      "41    0\n",
      "42    0\n",
      "43    0\n",
      "44    0\n",
      "45    0\n",
      "46    0\n",
      "47    0\n",
      "48    0\n",
      "49    0\n",
      "50    0\n",
      "51    0\n",
      "52    0\n",
      "53    0\n",
      "54    0\n",
      "55    0\n",
      "56    0\n",
      "57    0\n",
      "58    0\n",
      "59    0\n",
      "60    1\n",
      "dtype: int64\n",
      "checking train labels:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"checking train data features: \",sonar_data.isnull().sum())\n",
    "print(\"checking train labels: \",sonar_y.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sonar_data[60] = sonar_data[60].fillna(\"0:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.727139</td>\n",
       "      <td>-0.687098</td>\n",
       "      <td>-0.728647</td>\n",
       "      <td>-0.929149</td>\n",
       "      <td>-0.550089</td>\n",
       "      <td>-0.524859</td>\n",
       "      <td>-0.185065</td>\n",
       "      <td>-0.318192</td>\n",
       "      <td>-0.101436</td>\n",
       "      <td>-0.428571</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.537849</td>\n",
       "      <td>-0.945792</td>\n",
       "      <td>-0.688312</td>\n",
       "      <td>-0.128655</td>\n",
       "      <td>-0.70068</td>\n",
       "      <td>-0.164103</td>\n",
       "      <td>0.005682</td>\n",
       "      <td>-0.629291</td>\n",
       "      <td>-0.509642</td>\n",
       "      <td>-0.879908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.353982</td>\n",
       "      <td>-0.556794</td>\n",
       "      <td>-0.455979</td>\n",
       "      <td>-0.699952</td>\n",
       "      <td>-0.433934</td>\n",
       "      <td>0.333512</td>\n",
       "      <td>0.14881</td>\n",
       "      <td>0.510915</td>\n",
       "      <td>-0.033911</td>\n",
       "      <td>-0.210925</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.750996</td>\n",
       "      <td>-0.783167</td>\n",
       "      <td>-0.563636</td>\n",
       "      <td>-0.777778</td>\n",
       "      <td>-0.600907</td>\n",
       "      <td>-0.041026</td>\n",
       "      <td>-0.221591</td>\n",
       "      <td>-0.789474</td>\n",
       "      <td>-0.719008</td>\n",
       "      <td>-0.82448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.635693</td>\n",
       "      <td>-0.506215</td>\n",
       "      <td>-0.287779</td>\n",
       "      <td>-0.512601</td>\n",
       "      <td>-0.539944</td>\n",
       "      <td>0.170653</td>\n",
       "      <td>0.297619</td>\n",
       "      <td>0.638809</td>\n",
       "      <td>0.635717</td>\n",
       "      <td>0.739168</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.934263</td>\n",
       "      <td>-0.360913</td>\n",
       "      <td>-0.163636</td>\n",
       "      <td>-0.502924</td>\n",
       "      <td>-0.210884</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.778409</td>\n",
       "      <td>-0.263158</td>\n",
       "      <td>-0.482094</td>\n",
       "      <td>-0.667436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.874631</td>\n",
       "      <td>-0.858551</td>\n",
       "      <td>-0.600526</td>\n",
       "      <td>-0.9301</td>\n",
       "      <td>-0.930003</td>\n",
       "      <td>-0.857028</td>\n",
       "      <td>-0.423701</td>\n",
       "      <td>-0.461521</td>\n",
       "      <td>-0.845106</td>\n",
       "      <td>-0.670814</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.51992</td>\n",
       "      <td>-0.677603</td>\n",
       "      <td>-0.838961</td>\n",
       "      <td>-0.181287</td>\n",
       "      <td>-0.641723</td>\n",
       "      <td>-0.646154</td>\n",
       "      <td>-0.732955</td>\n",
       "      <td>-0.812357</td>\n",
       "      <td>-0.785124</td>\n",
       "      <td>-0.487298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.10177</td>\n",
       "      <td>-0.434205</td>\n",
       "      <td>-0.693824</td>\n",
       "      <td>-0.840228</td>\n",
       "      <td>-0.73472</td>\n",
       "      <td>-0.705993</td>\n",
       "      <td>-0.363636</td>\n",
       "      <td>0.063727</td>\n",
       "      <td>0.033319</td>\n",
       "      <td>0.242957</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.689243</td>\n",
       "      <td>-0.934379</td>\n",
       "      <td>-0.745455</td>\n",
       "      <td>-0.444444</td>\n",
       "      <td>-0.528345</td>\n",
       "      <td>-0.94359</td>\n",
       "      <td>-0.607955</td>\n",
       "      <td>-0.79405</td>\n",
       "      <td>-0.415978</td>\n",
       "      <td>-0.593533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>-0.746313</td>\n",
       "      <td>-0.70853</td>\n",
       "      <td>-0.899474</td>\n",
       "      <td>-0.943414</td>\n",
       "      <td>-0.834644</td>\n",
       "      <td>-0.178715</td>\n",
       "      <td>0.079546</td>\n",
       "      <td>-0.277178</td>\n",
       "      <td>-0.332741</td>\n",
       "      <td>-0.264693</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.595618</td>\n",
       "      <td>-0.691869</td>\n",
       "      <td>-0.516883</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>-0.877551</td>\n",
       "      <td>-0.502564</td>\n",
       "      <td>-0.647727</td>\n",
       "      <td>-0.487414</td>\n",
       "      <td>0.057851</td>\n",
       "      <td>-0.30254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>-0.545723</td>\n",
       "      <td>-0.91856</td>\n",
       "      <td>-0.81406</td>\n",
       "      <td>-0.759391</td>\n",
       "      <td>-0.648491</td>\n",
       "      <td>-0.539909</td>\n",
       "      <td>-0.482143</td>\n",
       "      <td>-0.575303</td>\n",
       "      <td>-0.717163</td>\n",
       "      <td>-0.416273</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.898406</td>\n",
       "      <td>-0.848787</td>\n",
       "      <td>-0.542857</td>\n",
       "      <td>-0.269006</td>\n",
       "      <td>-0.741497</td>\n",
       "      <td>-0.697436</td>\n",
       "      <td>-0.823864</td>\n",
       "      <td>-0.867277</td>\n",
       "      <td>-0.663912</td>\n",
       "      <td>-0.718245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>-0.252212</td>\n",
       "      <td>-0.630519</td>\n",
       "      <td>-0.89159</td>\n",
       "      <td>-0.88873</td>\n",
       "      <td>-0.855947</td>\n",
       "      <td>-0.425423</td>\n",
       "      <td>-0.337662</td>\n",
       "      <td>-0.504741</td>\n",
       "      <td>-0.649637</td>\n",
       "      <td>-0.309023</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.691235</td>\n",
       "      <td>-0.566334</td>\n",
       "      <td>-0.875325</td>\n",
       "      <td>-0.760234</td>\n",
       "      <td>-0.746032</td>\n",
       "      <td>-0.564103</td>\n",
       "      <td>-0.221591</td>\n",
       "      <td>-0.382151</td>\n",
       "      <td>-0.581267</td>\n",
       "      <td>-0.884527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>-0.575221</td>\n",
       "      <td>-0.702529</td>\n",
       "      <td>-0.687911</td>\n",
       "      <td>-0.738469</td>\n",
       "      <td>-0.949277</td>\n",
       "      <td>-0.327063</td>\n",
       "      <td>-0.225108</td>\n",
       "      <td>-0.528997</td>\n",
       "      <td>-0.446172</td>\n",
       "      <td>-0.359073</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.916335</td>\n",
       "      <td>-0.777461</td>\n",
       "      <td>-0.787013</td>\n",
       "      <td>-0.321637</td>\n",
       "      <td>-0.863946</td>\n",
       "      <td>-0.841026</td>\n",
       "      <td>-0.823864</td>\n",
       "      <td>-0.652174</td>\n",
       "      <td>-0.807163</td>\n",
       "      <td>-0.806005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>-0.638643</td>\n",
       "      <td>-0.693956</td>\n",
       "      <td>-0.920499</td>\n",
       "      <td>-0.898241</td>\n",
       "      <td>-0.925437</td>\n",
       "      <td>-0.873152</td>\n",
       "      <td>-0.66342</td>\n",
       "      <td>-0.406836</td>\n",
       "      <td>-0.476381</td>\n",
       "      <td>-0.359073</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.639442</td>\n",
       "      <td>-0.606277</td>\n",
       "      <td>-0.355844</td>\n",
       "      <td>-0.783626</td>\n",
       "      <td>-0.85034</td>\n",
       "      <td>-0.707692</td>\n",
       "      <td>-0.789773</td>\n",
       "      <td>-0.84897</td>\n",
       "      <td>-0.669421</td>\n",
       "      <td>-0.496536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           1         2         3         4         5         6         7   \\\n",
       "0   -0.727139 -0.687098 -0.728647 -0.929149 -0.550089 -0.524859 -0.185065   \n",
       "1   -0.353982 -0.556794 -0.455979 -0.699952 -0.433934  0.333512   0.14881   \n",
       "2   -0.635693 -0.506215 -0.287779 -0.512601 -0.539944  0.170653  0.297619   \n",
       "3   -0.874631 -0.858551 -0.600526   -0.9301 -0.930003 -0.857028 -0.423701   \n",
       "4     0.10177 -0.434205 -0.693824 -0.840228  -0.73472 -0.705993 -0.363636   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "203 -0.746313  -0.70853 -0.899474 -0.943414 -0.834644 -0.178715  0.079546   \n",
       "204 -0.545723  -0.91856  -0.81406 -0.759391 -0.648491 -0.539909 -0.482143   \n",
       "205 -0.252212 -0.630519  -0.89159  -0.88873 -0.855947 -0.425423 -0.337662   \n",
       "206 -0.575221 -0.702529 -0.687911 -0.738469 -0.949277 -0.327063 -0.225108   \n",
       "207 -0.638643 -0.693956 -0.920499 -0.898241 -0.925437 -0.873152  -0.66342   \n",
       "\n",
       "           8         9         10  ...        51        52        53  \\\n",
       "0   -0.318192 -0.101436 -0.428571  ... -0.537849 -0.945792 -0.688312   \n",
       "1    0.510915 -0.033911 -0.210925  ... -0.750996 -0.783167 -0.563636   \n",
       "2    0.638809  0.635717  0.739168  ... -0.934263 -0.360913 -0.163636   \n",
       "3   -0.461521 -0.845106 -0.670814  ...  -0.51992 -0.677603 -0.838961   \n",
       "4    0.063727  0.033319  0.242957  ... -0.689243 -0.934379 -0.745455   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "203 -0.277178 -0.332741 -0.264693  ... -0.595618 -0.691869 -0.516883   \n",
       "204 -0.575303 -0.717163 -0.416273  ... -0.898406 -0.848787 -0.542857   \n",
       "205 -0.504741 -0.649637 -0.309023  ... -0.691235 -0.566334 -0.875325   \n",
       "206 -0.528997 -0.446172 -0.359073  ... -0.916335 -0.777461 -0.787013   \n",
       "207 -0.406836 -0.476381 -0.359073  ... -0.639442 -0.606277 -0.355844   \n",
       "\n",
       "           54        55        56        57        58        59        60  \n",
       "0   -0.128655  -0.70068 -0.164103  0.005682 -0.629291 -0.509642 -0.879908  \n",
       "1   -0.777778 -0.600907 -0.041026 -0.221591 -0.789474 -0.719008  -0.82448  \n",
       "2   -0.502924 -0.210884  0.230769  0.778409 -0.263158 -0.482094 -0.667436  \n",
       "3   -0.181287 -0.641723 -0.646154 -0.732955 -0.812357 -0.785124 -0.487298  \n",
       "4   -0.444444 -0.528345  -0.94359 -0.607955  -0.79405 -0.415978 -0.593533  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "203  0.105263 -0.877551 -0.502564 -0.647727 -0.487414  0.057851  -0.30254  \n",
       "204 -0.269006 -0.741497 -0.697436 -0.823864 -0.867277 -0.663912 -0.718245  \n",
       "205 -0.760234 -0.746032 -0.564103 -0.221591 -0.382151 -0.581267 -0.884527  \n",
       "206 -0.321637 -0.863946 -0.841026 -0.823864 -0.652174 -0.807163 -0.806005  \n",
       "207 -0.783626  -0.85034 -0.707692 -0.789773  -0.84897 -0.669421 -0.496536  \n",
       "\n",
       "[208 rows x 60 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing the colons and fetching required values in our dataset\n",
    "for i in sonar_data:\n",
    "    for j in range(len(sonar_data[i])):\n",
    "        #print(sonar_data[i][j])\n",
    "        m,n = sonar_data[i][j].split(':')\n",
    "        sonar_data[i][j] = float(n)\n",
    "sonar_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 10,\n",
       " 13,\n",
       " 15,\n",
       " 16,\n",
       " 20,\n",
       " 21,\n",
       " 24,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 36,\n",
       " 37,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 71,\n",
       " 73,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 82,\n",
       " 83,\n",
       " 85,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 106,\n",
       " 107,\n",
       " 108,\n",
       " 109,\n",
       " 110,\n",
       " 111,\n",
       " 112,\n",
       " 114,\n",
       " 116,\n",
       " 118,\n",
       " 119,\n",
       " 120,\n",
       " 122,\n",
       " 126,\n",
       " 127,\n",
       " 128,\n",
       " 130,\n",
       " 132,\n",
       " 133,\n",
       " 134,\n",
       " 135,\n",
       " 137,\n",
       " 138,\n",
       " 139,\n",
       " 141,\n",
       " 142,\n",
       " 143,\n",
       " 144,\n",
       " 145,\n",
       " 146,\n",
       " 147,\n",
       " 148,\n",
       " 149,\n",
       " 150,\n",
       " 151,\n",
       " 154,\n",
       " 155,\n",
       " 156,\n",
       " 158,\n",
       " 159,\n",
       " 161,\n",
       " 162,\n",
       " 163,\n",
       " 164,\n",
       " 165,\n",
       " 168,\n",
       " 169,\n",
       " 170,\n",
       " 171,\n",
       " 173,\n",
       " 174,\n",
       " 175,\n",
       " 176,\n",
       " 177,\n",
       " 178,\n",
       " 179,\n",
       " 180,\n",
       " 181,\n",
       " 182,\n",
       " 183,\n",
       " 184,\n",
       " 185,\n",
       " 186,\n",
       " 187,\n",
       " 189,\n",
       " 192,\n",
       " 193,\n",
       " 194,\n",
       " 195,\n",
       " 196,\n",
       " 197,\n",
       " 200,\n",
       " 201,\n",
       " 203,\n",
       " 204,\n",
       " 207]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainIndex_sonar = pd.read_csv(\"C:\\\\Users\\\\Rahul\\\\Documents\\\\CS-688\\\\data_assignment4\\\\data_assignment4\\\\sonar-scale-train-indices.txt\", header=None)\n",
    "trainIndexlist_sonar = []\n",
    "for i,ind in enumerate(trainIndex_sonar[:][0]):\n",
    "  trainIndexlist_sonar.append(ind-1)\n",
    "#trainIndex.head()\n",
    "trainIndexlist_sonar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.635693</td>\n",
       "      <td>-0.506215</td>\n",
       "      <td>-0.287779</td>\n",
       "      <td>-0.512601</td>\n",
       "      <td>-0.539944</td>\n",
       "      <td>0.170653</td>\n",
       "      <td>0.297619</td>\n",
       "      <td>0.638809</td>\n",
       "      <td>0.635717</td>\n",
       "      <td>0.739168</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.934263</td>\n",
       "      <td>-0.360913</td>\n",
       "      <td>-0.163636</td>\n",
       "      <td>-0.502924</td>\n",
       "      <td>-0.210884</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.778409</td>\n",
       "      <td>-0.263158</td>\n",
       "      <td>-0.482094</td>\n",
       "      <td>-0.667436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.10177</td>\n",
       "      <td>-0.434205</td>\n",
       "      <td>-0.693824</td>\n",
       "      <td>-0.840228</td>\n",
       "      <td>-0.73472</td>\n",
       "      <td>-0.705993</td>\n",
       "      <td>-0.363636</td>\n",
       "      <td>0.063727</td>\n",
       "      <td>0.033319</td>\n",
       "      <td>0.242957</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.689243</td>\n",
       "      <td>-0.934379</td>\n",
       "      <td>-0.745455</td>\n",
       "      <td>-0.444444</td>\n",
       "      <td>-0.528345</td>\n",
       "      <td>-0.94359</td>\n",
       "      <td>-0.607955</td>\n",
       "      <td>-0.79405</td>\n",
       "      <td>-0.415978</td>\n",
       "      <td>-0.593533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.600295</td>\n",
       "      <td>-0.616802</td>\n",
       "      <td>-0.827858</td>\n",
       "      <td>-0.944841</td>\n",
       "      <td>-0.839209</td>\n",
       "      <td>-0.522709</td>\n",
       "      <td>-0.367965</td>\n",
       "      <td>-0.215877</td>\n",
       "      <td>-0.398786</td>\n",
       "      <td>-0.163163</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.792829</td>\n",
       "      <td>-0.894437</td>\n",
       "      <td>-0.953247</td>\n",
       "      <td>-0.836257</td>\n",
       "      <td>-0.968254</td>\n",
       "      <td>-0.564103</td>\n",
       "      <td>-0.693182</td>\n",
       "      <td>-0.89016</td>\n",
       "      <td>-0.724518</td>\n",
       "      <td>-0.741339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.554572</td>\n",
       "      <td>-0.185598</td>\n",
       "      <td>-0.141919</td>\n",
       "      <td>-0.35806</td>\n",
       "      <td>-0.184885</td>\n",
       "      <td>-0.135716</td>\n",
       "      <td>-0.622294</td>\n",
       "      <td>-0.406395</td>\n",
       "      <td>-0.405301</td>\n",
       "      <td>-0.027599</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.611554</td>\n",
       "      <td>-0.449358</td>\n",
       "      <td>0.262338</td>\n",
       "      <td>-0.292398</td>\n",
       "      <td>-0.709751</td>\n",
       "      <td>-0.312821</td>\n",
       "      <td>-0.494318</td>\n",
       "      <td>-0.359268</td>\n",
       "      <td>-0.807163</td>\n",
       "      <td>-0.551963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.256637</td>\n",
       "      <td>-0.535362</td>\n",
       "      <td>-0.456636</td>\n",
       "      <td>-0.875892</td>\n",
       "      <td>-0.446614</td>\n",
       "      <td>-0.559258</td>\n",
       "      <td>-0.462121</td>\n",
       "      <td>-0.753914</td>\n",
       "      <td>-0.588331</td>\n",
       "      <td>-0.220649</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.896414</td>\n",
       "      <td>-0.791726</td>\n",
       "      <td>-0.402597</td>\n",
       "      <td>-0.795322</td>\n",
       "      <td>-0.478458</td>\n",
       "      <td>-0.523077</td>\n",
       "      <td>-0.534091</td>\n",
       "      <td>-0.798627</td>\n",
       "      <td>-0.741047</td>\n",
       "      <td>-0.78291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         1         2         3         4         5         6         7   \\\n",
       "0 -0.635693 -0.506215 -0.287779 -0.512601 -0.539944  0.170653  0.297619   \n",
       "1   0.10177 -0.434205 -0.693824 -0.840228  -0.73472 -0.705993 -0.363636   \n",
       "2 -0.600295 -0.616802 -0.827858 -0.944841 -0.839209 -0.522709 -0.367965   \n",
       "3 -0.554572 -0.185598 -0.141919  -0.35806 -0.184885 -0.135716 -0.622294   \n",
       "4 -0.256637 -0.535362 -0.456636 -0.875892 -0.446614 -0.559258 -0.462121   \n",
       "\n",
       "         8         9         10  ...        51        52        53        54  \\\n",
       "0  0.638809  0.635717  0.739168  ... -0.934263 -0.360913 -0.163636 -0.502924   \n",
       "1  0.063727  0.033319  0.242957  ... -0.689243 -0.934379 -0.745455 -0.444444   \n",
       "2 -0.215877 -0.398786 -0.163163  ... -0.792829 -0.894437 -0.953247 -0.836257   \n",
       "3 -0.406395 -0.405301 -0.027599  ... -0.611554 -0.449358  0.262338 -0.292398   \n",
       "4 -0.753914 -0.588331 -0.220649  ... -0.896414 -0.791726 -0.402597 -0.795322   \n",
       "\n",
       "         55        56        57        58        59        60  \n",
       "0 -0.210884  0.230769  0.778409 -0.263158 -0.482094 -0.667436  \n",
       "1 -0.528345  -0.94359 -0.607955  -0.79405 -0.415978 -0.593533  \n",
       "2 -0.968254 -0.564103 -0.693182  -0.89016 -0.724518 -0.741339  \n",
       "3 -0.709751 -0.312821 -0.494318 -0.359268 -0.807163 -0.551963  \n",
       "4 -0.478458 -0.523077 -0.534091 -0.798627 -0.741047  -0.78291  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splitting the train data from the main data set based on train indices.\n",
    "trainData_sonar = sonar_data.iloc[trainIndexlist_sonar,:]\n",
    "trainData_sonar = trainData_sonar.reset_index(drop=True)\n",
    "trainData_sonar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting the train labels\n",
    "trainLabels_sonar = sonar_y.iloc[trainIndexlist_sonar]\n",
    "trainLabels_sonar = trainLabels_sonar.reset_index(drop=True)\n",
    "trainLabels_sonar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 3,\n",
       " 8,\n",
       " 9,\n",
       " 11,\n",
       " 12,\n",
       " 14,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 22,\n",
       " 23,\n",
       " 25,\n",
       " 35,\n",
       " 38,\n",
       " 42,\n",
       " 43,\n",
       " 49,\n",
       " 56,\n",
       " 64,\n",
       " 65,\n",
       " 70,\n",
       " 72,\n",
       " 74,\n",
       " 81,\n",
       " 84,\n",
       " 86,\n",
       " 87,\n",
       " 93,\n",
       " 94,\n",
       " 101,\n",
       " 113,\n",
       " 115,\n",
       " 117,\n",
       " 121,\n",
       " 123,\n",
       " 124,\n",
       " 125,\n",
       " 129,\n",
       " 131,\n",
       " 136,\n",
       " 140,\n",
       " 152,\n",
       " 153,\n",
       " 157,\n",
       " 160,\n",
       " 166,\n",
       " 167,\n",
       " 172,\n",
       " 188,\n",
       " 190,\n",
       " 191,\n",
       " 198,\n",
       " 199,\n",
       " 202,\n",
       " 205,\n",
       " 206]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting the test data indices\n",
    "testIndex_sonar = pd.read_csv(\"C:\\\\Users\\\\Rahul\\\\Documents\\\\CS-688\\\\data_assignment4\\\\data_assignment4\\\\sonar-scale-test-indices.txt\", header=None)\n",
    "testIndexlist_sonar = []\n",
    "for i,ind in enumerate(testIndex_sonar[:][0]):\n",
    "  testIndexlist_sonar.append(ind-1)\n",
    "testIndexlist_sonar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.727139</td>\n",
       "      <td>-0.687098</td>\n",
       "      <td>-0.728647</td>\n",
       "      <td>-0.929149</td>\n",
       "      <td>-0.550089</td>\n",
       "      <td>-0.524859</td>\n",
       "      <td>-0.185065</td>\n",
       "      <td>-0.318192</td>\n",
       "      <td>-0.101436</td>\n",
       "      <td>-0.428571</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.537849</td>\n",
       "      <td>-0.945792</td>\n",
       "      <td>-0.688312</td>\n",
       "      <td>-0.128655</td>\n",
       "      <td>-0.70068</td>\n",
       "      <td>-0.164103</td>\n",
       "      <td>0.005682</td>\n",
       "      <td>-0.629291</td>\n",
       "      <td>-0.509642</td>\n",
       "      <td>-0.879908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.353982</td>\n",
       "      <td>-0.556794</td>\n",
       "      <td>-0.455979</td>\n",
       "      <td>-0.699952</td>\n",
       "      <td>-0.433934</td>\n",
       "      <td>0.333512</td>\n",
       "      <td>0.14881</td>\n",
       "      <td>0.510915</td>\n",
       "      <td>-0.033911</td>\n",
       "      <td>-0.210925</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.750996</td>\n",
       "      <td>-0.783167</td>\n",
       "      <td>-0.563636</td>\n",
       "      <td>-0.777778</td>\n",
       "      <td>-0.600907</td>\n",
       "      <td>-0.041026</td>\n",
       "      <td>-0.221591</td>\n",
       "      <td>-0.789474</td>\n",
       "      <td>-0.719008</td>\n",
       "      <td>-0.82448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.874631</td>\n",
       "      <td>-0.858551</td>\n",
       "      <td>-0.600526</td>\n",
       "      <td>-0.9301</td>\n",
       "      <td>-0.930003</td>\n",
       "      <td>-0.857028</td>\n",
       "      <td>-0.423701</td>\n",
       "      <td>-0.461521</td>\n",
       "      <td>-0.845106</td>\n",
       "      <td>-0.670814</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.51992</td>\n",
       "      <td>-0.677603</td>\n",
       "      <td>-0.838961</td>\n",
       "      <td>-0.181287</td>\n",
       "      <td>-0.641723</td>\n",
       "      <td>-0.646154</td>\n",
       "      <td>-0.732955</td>\n",
       "      <td>-0.812357</td>\n",
       "      <td>-0.785124</td>\n",
       "      <td>-0.487298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.693215</td>\n",
       "      <td>-0.683669</td>\n",
       "      <td>-0.691853</td>\n",
       "      <td>-0.801712</td>\n",
       "      <td>-0.705808</td>\n",
       "      <td>-0.737167</td>\n",
       "      <td>-0.61039</td>\n",
       "      <td>-0.981036</td>\n",
       "      <td>-0.819636</td>\n",
       "      <td>-0.607036</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.878486</td>\n",
       "      <td>-0.60913</td>\n",
       "      <td>-0.361039</td>\n",
       "      <td>-0.210526</td>\n",
       "      <td>-0.764172</td>\n",
       "      <td>-0.769231</td>\n",
       "      <td>-0.647727</td>\n",
       "      <td>-0.588101</td>\n",
       "      <td>-0.680441</td>\n",
       "      <td>-0.926097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.780236</td>\n",
       "      <td>-0.856837</td>\n",
       "      <td>-0.781866</td>\n",
       "      <td>-0.994294</td>\n",
       "      <td>-0.939133</td>\n",
       "      <td>-0.694168</td>\n",
       "      <td>-0.446429</td>\n",
       "      <td>-0.716869</td>\n",
       "      <td>-0.737302</td>\n",
       "      <td>-0.960532</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.76494</td>\n",
       "      <td>-0.766049</td>\n",
       "      <td>0.132468</td>\n",
       "      <td>-0.011696</td>\n",
       "      <td>-0.646259</td>\n",
       "      <td>-0.671795</td>\n",
       "      <td>-0.835227</td>\n",
       "      <td>-0.853547</td>\n",
       "      <td>-0.69697</td>\n",
       "      <td>-0.842956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         1         2         3         4         5         6         7   \\\n",
       "0 -0.727139 -0.687098 -0.728647 -0.929149 -0.550089 -0.524859 -0.185065   \n",
       "1 -0.353982 -0.556794 -0.455979 -0.699952 -0.433934  0.333512   0.14881   \n",
       "2 -0.874631 -0.858551 -0.600526   -0.9301 -0.930003 -0.857028 -0.423701   \n",
       "3 -0.693215 -0.683669 -0.691853 -0.801712 -0.705808 -0.737167  -0.61039   \n",
       "4 -0.780236 -0.856837 -0.781866 -0.994294 -0.939133 -0.694168 -0.446429   \n",
       "\n",
       "         8         9         10  ...        51        52        53        54  \\\n",
       "0 -0.318192 -0.101436 -0.428571  ... -0.537849 -0.945792 -0.688312 -0.128655   \n",
       "1  0.510915 -0.033911 -0.210925  ... -0.750996 -0.783167 -0.563636 -0.777778   \n",
       "2 -0.461521 -0.845106 -0.670814  ...  -0.51992 -0.677603 -0.838961 -0.181287   \n",
       "3 -0.981036 -0.819636 -0.607036  ... -0.878486  -0.60913 -0.361039 -0.210526   \n",
       "4 -0.716869 -0.737302 -0.960532  ...  -0.76494 -0.766049  0.132468 -0.011696   \n",
       "\n",
       "         55        56        57        58        59        60  \n",
       "0  -0.70068 -0.164103  0.005682 -0.629291 -0.509642 -0.879908  \n",
       "1 -0.600907 -0.041026 -0.221591 -0.789474 -0.719008  -0.82448  \n",
       "2 -0.641723 -0.646154 -0.732955 -0.812357 -0.785124 -0.487298  \n",
       "3 -0.764172 -0.769231 -0.647727 -0.588101 -0.680441 -0.926097  \n",
       "4 -0.646259 -0.671795 -0.835227 -0.853547  -0.69697 -0.842956  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splitting the test data from the main data set based on test indices.\n",
    "testData_sonar = sonar_data.iloc[testIndexlist_sonar,:]\n",
    "testData_sonar = testData_sonar.reset_index(drop=True)\n",
    "testData_sonar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    2\n",
       "2    2\n",
       "3    2\n",
       "4    2\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting the test labels\n",
    "testLabels_sonar = sonar_y.iloc[testIndexlist_sonar]\n",
    "testLabels_sonar = testLabels_sonar.reset_index(drop=True)\n",
    "testLabels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## splitting and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sonar, X_test_sonar, y_train_sonar, y_test_sonar = train_test_split(trainData_sonar, trainLabels_sonar, random_state=47, stratify = trainLabels_sonar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find best C using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accuracy',\n",
       " 'adjusted_mutual_info_score',\n",
       " 'adjusted_rand_score',\n",
       " 'average_precision',\n",
       " 'balanced_accuracy',\n",
       " 'completeness_score',\n",
       " 'explained_variance',\n",
       " 'f1',\n",
       " 'f1_macro',\n",
       " 'f1_micro',\n",
       " 'f1_samples',\n",
       " 'f1_weighted',\n",
       " 'fowlkes_mallows_score',\n",
       " 'homogeneity_score',\n",
       " 'jaccard',\n",
       " 'jaccard_macro',\n",
       " 'jaccard_micro',\n",
       " 'jaccard_samples',\n",
       " 'jaccard_weighted',\n",
       " 'max_error',\n",
       " 'mutual_info_score',\n",
       " 'neg_brier_score',\n",
       " 'neg_log_loss',\n",
       " 'neg_mean_absolute_error',\n",
       " 'neg_mean_absolute_percentage_error',\n",
       " 'neg_mean_gamma_deviance',\n",
       " 'neg_mean_poisson_deviance',\n",
       " 'neg_mean_squared_error',\n",
       " 'neg_mean_squared_log_error',\n",
       " 'neg_median_absolute_error',\n",
       " 'neg_root_mean_squared_error',\n",
       " 'normalized_mutual_info_score',\n",
       " 'precision',\n",
       " 'precision_macro',\n",
       " 'precision_micro',\n",
       " 'precision_samples',\n",
       " 'precision_weighted',\n",
       " 'r2',\n",
       " 'rand_score',\n",
       " 'recall',\n",
       " 'recall_macro',\n",
       " 'recall_micro',\n",
       " 'recall_samples',\n",
       " 'recall_weighted',\n",
       " 'roc_auc',\n",
       " 'roc_auc_ovo',\n",
       " 'roc_auc_ovo_weighted',\n",
       " 'roc_auc_ovr',\n",
       " 'roc_auc_ovr_weighted',\n",
       " 'top_k_accuracy',\n",
       " 'v_measure_score']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sorted(sklearn.metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_values = [0.1,1,10,100,1000]\n",
    "meanErrorsTraining_sonar = []\n",
    "meanErrorsValidation_sonar = []\n",
    "kfold = KFold(n_splits=5, random_state=27, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findMeanSquaredErrorForC(kfold, c, X, y):\n",
    "  lr = LogisticRegression(random_state=27, C=c, solver='liblinear')\n",
    "  result = cross_val_score(lr, X, y, cv=kfold, scoring='neg_mean_squared_error')\n",
    "  return result.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in c_values:\n",
    "  meanErrorsTraining_sonar.append(findMeanSquaredErrorForC(kfold, c, X_train_sonar, y_train_sonar))\n",
    "  meanErrorsValidation_sonar.append(findMeanSquaredErrorForC(kfold, c, X_test_sonar, y_test_sonar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors on training data for different values of c:  [-1.0039525691699605, -1.0023715415019763, -0.9976284584980238, -0.9264822134387352, -0.9264822134387352]\n",
      "Errors on validation data for different values of c:  [-1.5, -1.4, -1.3, -1.6, -1.6857142857142855]\n"
     ]
    }
   ],
   "source": [
    "print(\"Errors on training data for different values of c: \", meanErrorsTraining_sonar)\n",
    "print(\"Errors on validation data for different values of c: \", meanErrorsValidation_sonar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best value of C:  10\n"
     ]
    }
   ],
   "source": [
    "best_value_of_c = c_values[np.argsort(-np.array(meanErrorsValidation_sonar))[0]]\n",
    "print(\"best value of C: \", best_value_of_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model using best C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for cancer data with best C is:  0.7758620689655172\n"
     ]
    }
   ],
   "source": [
    "bestLR = LogisticRegression(random_state=27, C=10, solver='liblinear').fit(trainData_sonar, trainLabels_sonar)\n",
    "y_predLR = bestLR.predict(testData_sonar)\n",
    "print(\"accuracy for cancer data with best C is: \", accuracy_score(y_predLR, testLabels_sonar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error rate for testing data:  22.413793103448278 %\n"
     ]
    }
   ],
   "source": [
    "error = 0\n",
    "for i in range(len(y_predLR)):\n",
    "  if y_predLR[i] != testLabels_sonar[i]:\n",
    "    error = error + 1\n",
    "print(\"error rate for testing data: \", error/len(y_predLR)*100, \"%\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_error_sonar_svm = []\n",
    "validation_error_sonar_svm = []\n",
    "kf = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hingeLoss(y_true, y_predict):\n",
    "  return hinge_loss(y_true, y_predict)\n",
    "\n",
    "hingeLossMetric = make_scorer(hingeLoss, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in c_values:\n",
    "  linear_svm = LinearSVC(random_state=0,C=i)\n",
    "  result = cross_val_score(linear_svm, X_train, y_train, cv=kf, scoring=hingeLossMetric)\n",
    "  training_error_sonar_svm.append(result.mean())\n",
    "  \n",
    "  result = cross_val_score(linear_svm, X_test, y_test, cv=kf, scoring=hingeLossMetric)\n",
    "  validation_error_sonar_svm.append(result.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainning data errors: [-1.984, -1.984, -1.984, -1.984, -2.1173333333333333]\n",
      "Validation data errors: [-1.9439999999999997, -1.9439999999999997, -1.9439999999999997, -1.9439999999999997, -1.9439999999999997]\n"
     ]
    }
   ],
   "source": [
    "print(\"Trainning data errors:\", training_error_sonar_svm)\n",
    "print(\"Validation data errors:\", validation_error_sonar_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n"
     ]
    }
   ],
   "source": [
    "best_value_of_c = c_values[validation_error_sonar_svm.index(min(validation_error_sonar_svm))]\n",
    "print(best_value_of_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hinge Loss for testing data:  0.5172413793103449\n"
     ]
    }
   ],
   "source": [
    "lr1 = LinearSVC(random_state=0,C=0.1).fit(trainData_sonar, trainLabels_sonar)\n",
    "lr1_pred = lr1.predict(testData_sonar)\n",
    "accuracy = accuracy_score(lr1_pred, testLabels_sonar)\n",
    "\n",
    "error = 0\n",
    "for i in range(len(lr1_pred)):\n",
    "  if lr1_pred[i] != testLabels_sonar[i]:\n",
    "    error = error + 1\n",
    "error_rate = error/len(lr1_pred)*100\n",
    "print(\"Hinge Loss for testing data: \", hinge_loss(testLabels_sonar,lr1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7413793103448276\n",
      "Error rate: 25.862068965517242\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Error rate:\", error_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_error_sonar_poly = []\n",
    "validation_error_sonar_poly = []\n",
    "kf = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in c_values:\n",
    "  poly_svm = SVC(random_state=0, C=i,kernel='poly')\n",
    "  result = cross_val_score(poly_svm, X_train, y_train, cv=kf, scoring=hingeLossMetric)\n",
    "  training_error_sonar_poly.append(result.mean())\n",
    "  \n",
    "  result = cross_val_score(poly_svm, X_test, y_test, cv=kf, scoring=hingeLossMetric)\n",
    "  validation_error_sonar_poly.append(result.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainning data errors: [-1.9893333333333334, -2.0, -2.0053333333333336, -2.0053333333333336, -2.0053333333333336]\n",
      "Validation data errors: [-1.9759999999999998, -1.9599999999999997, -1.9439999999999997, -1.9439999999999997, -1.9439999999999997]\n"
     ]
    }
   ],
   "source": [
    "print(\"Trainning data errors:\", training_error_sonar_poly)\n",
    "print(\"Validation data errors:\", validation_error_sonar_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n"
     ]
    }
   ],
   "source": [
    "best_value_of_c = c_values[validation_error_sonar_poly.index(min(validation_error_sonar_poly))]\n",
    "print(best_value_of_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hinge Loss for testing data:  0.6206896551724138\n"
     ]
    }
   ],
   "source": [
    "lr1 = SVC(random_state=0,C=0.1, kernel='poly').fit(trainData_sonar, trainLabels_sonar)\n",
    "lr1_pred = lr1.predict(testData_sonar)\n",
    "accuracy = accuracy_score(lr1_pred, testLabels_sonar)\n",
    "\n",
    "error = 0\n",
    "for i in range(len(lr1_pred)):\n",
    "  if lr1_pred[i] != testLabels_sonar[i]:\n",
    "    error = error + 1\n",
    "error_rate = error/len(lr1_pred)*100\n",
    "print(\"Hinge Loss for testing data: \", hinge_loss(testLabels_sonar,lr1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6896551724137931\n",
      "Error rate: 31.03448275862069\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Error rate:\", error_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RBF Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_error_sonar_rbf = []\n",
    "validation_error_sonar_rbf = []\n",
    "kf = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in c_values:\n",
    "  rbf_svm = SVC(random_state=0, C=i,kernel='rbf')\n",
    "  result = cross_val_score(rbf_svm, X_train, y_train, cv=kf, scoring=hingeLossMetric)\n",
    "  training_error_sonar_rbf.append(result.mean())\n",
    "  \n",
    "  result = cross_val_score(rbf_svm, X_test, y_test, cv=kf, scoring=hingeLossMetric)\n",
    "  validation_error_sonar_rbf.append(result.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainning data errors: [-1.9946666666666666, -1.9893333333333334, -1.9946666666666668, -2.0, -2.0]\n",
      "Validation data errors: [-1.9599999999999997, -1.9439999999999997, -1.9439999999999997, -1.9439999999999997, -1.9439999999999997]\n"
     ]
    }
   ],
   "source": [
    "print(\"Trainning data errors:\", training_error_sonar_rbf)\n",
    "print(\"Validation data errors:\", validation_error_sonar_rbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n"
     ]
    }
   ],
   "source": [
    "best_value_of_c = c_values[validation_error_sonar_rbf.index(min(validation_error_sonar_rbf))]\n",
    "print(best_value_of_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hinge Loss for testing data:  1.0689655172413792\n"
     ]
    }
   ],
   "source": [
    "lr1 = SVC(random_state=0,C=0.1, kernel='rbf').fit(trainData_sonar, trainLabels_sonar)\n",
    "lr1_pred = lr1.predict(testData_sonar)\n",
    "accuracy = accuracy_score(lr1_pred, testLabels_sonar)\n",
    "\n",
    "error = 0\n",
    "for i in range(len(lr1_pred)):\n",
    "  if lr1_pred[i] != testLabels_sonar[i]:\n",
    "    error = error + 1\n",
    "error_rate = error/len(lr1_pred)*100\n",
    "print(\"Hinge Loss for testing data: \", hinge_loss(testLabels_sonar,lr1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.46551724137931033\n",
      "Error rate: 53.44827586206896\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Error rate:\", error_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer_dataset_error_rate = [3.8251, 3.8251, 3.2787, 3.8251]\n",
    "sonar_dataset_error_rate = [22.4138, 25.8621, 31.0345, 53.4482]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# creating the dataset\n",
    "breast_cancer_dataset_error_rate = {'logistic regression':3.8251, 'Linear SVM':3.8251, 'Polynomial Kernal SVM':3.2787,\n",
    "\t\t'RBF Kernal SVM':3.8251}\n",
    "model = list(breast_cancer_dataset_error_rate.keys())\n",
    "values = list(breast_cancer_dataset_error_rate.values())\n",
    "\n",
    "fig = plt.figure(figsize = (10, 5))\n",
    "\n",
    "# creating the bar plot\n",
    "plt.bar(model, values, color ='violet',\n",
    "\t\twidth = 0.4)\n",
    "\n",
    "plt.xlabel(\"Models used\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# creating the dataset\n",
    "sonar_scale_dataset_error_rate = {'logistic regression':22.4138, 'Linear SVM':25.8621, 'Polynomial Kernal SVM':31.0345,\n",
    "\t\t'RBF Kernal SVM':53.4482}\n",
    "model = list(sonar_scale_dataset_error_rate.keys())\n",
    "values = list(sonar_scale_dataset_error_rate.values())\n",
    "\n",
    "fig = plt.figure(figsize = (10, 5))\n",
    "\n",
    "# creating the bar plot\n",
    "plt.bar(model, values, color ='orange',\n",
    "\t\twidth = 0.4)\n",
    "\n",
    "plt.xlabel(\"Models used\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "nbAemhDaq4xs",
    "MixQT3M34YhJ"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
